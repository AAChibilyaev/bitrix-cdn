#!/usr/bin/env python3
"""
AI-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è —Å–∏—Å—Ç–µ–º—ã CDN —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT
"""

import logging
import openai
from typing import Dict, Any, List, Optional
from bot.prometheus_client import PrometheusClient
from bot.docker_client import DockerClient
from bot.types import (
    AppConfig, ContainerInfo, HealthCheckResult, AllMetrics, 
    CacheStatistics, AIAnalysisResult, Alert, NotificationIssue
)
from bot.ai_cache import analysis_cache

logger = logging.getLogger(__name__)

class AIAnalyzer:
    """AI-–∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å–∏—Å—Ç–µ–º—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self.prometheus = PrometheusClient(config)
        self.docker = DockerClient(config)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ OpenAI
        openai.api_key = config.openai.api_key
        self.model = config.openai.model
        
        logger.info("AI Analyzer initialized")
    
    async def analyze_system(self, use_cache: bool = True) -> AIAnalysisResult:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ AI-–∞–Ω–∞–ª–∏–∑–∞ —Å–∏—Å—Ç–µ–º—ã —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        try:
            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Å–∏—Å—Ç–µ–º–µ
            metrics = await self.prometheus.get_all_metrics()
            containers = await self.docker.get_containers_status()
            health_checks = await self.docker.get_health_checks()
            cache_stats = await self.docker.get_cache_statistics()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è GPT
            context = self._prepare_context(metrics, containers, health_checks, cache_stats)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
            if use_cache:
                cached_result = await analysis_cache.get(context)
                if cached_result:
                    logger.info("Using cached AI analysis result")
                    return cached_result
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —Å GPT
            analysis_text = await self._perform_gpt_analysis(context)
            
            # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            result = self._parse_analysis_result(analysis_text)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
            if use_cache:
                await analysis_cache.set(context, result)
            
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ AI-–∞–Ω–∞–ª–∏–∑–∞: {e}")
            return AIAnalysisResult(
                status="error",
                problems=[f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è AI-–∞–Ω–∞–ª–∏–∑–∞: {e}"],
                recommendations=[],
                performance_score=None,
                forecast=None
            )
    
    def _prepare_context(self, metrics: Dict, containers: List, health_checks: Dict, cache_stats: Dict) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è GPT"""
        context = "=== –ê–ù–ê–õ–ò–ó –°–ò–°–¢–ï–ú–´ CDN ===\n\n"
        
        # –°—Ç–∞—Ç—É—Å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        context += "üê≥ –ö–û–ù–¢–ï–ô–ù–ï–†–´:\n"
        for container in containers:
            status_emoji = "‚úÖ" if container['status'] == 'running' else "‚ùå"
            context += f"{status_emoji} {container['name']}: {container['status']}\n"
            if container.get('health'):
                context += f"   Health: {container['health']}\n"
        context += "\n"
        
        # Health checks
        context += "üè• HEALTH CHECKS:\n"
        for service, status in health_checks.items():
            status_emoji = "‚úÖ" if status['healthy'] else "‚ùå"
            context += f"{status_emoji} {service}: {status['status']}\n"
        context += "\n"
        
        # –ú–µ—Ç—Ä–∏–∫–∏ Nginx
        if metrics.get('nginx'):
            nginx_metrics = metrics['nginx']
            context += "üåê NGINX –ú–ï–¢–†–ò–ö–ò:\n"
            for metric, value in nginx_metrics.items():
                if value and value != 'N/A':
                    context += f"   {metric}: {value}\n"
            context += "\n"
        
        # –ú–µ—Ç—Ä–∏–∫–∏ Redis
        if metrics.get('redis'):
            redis_metrics = metrics['redis']
            context += "üíæ REDIS –ú–ï–¢–†–ò–ö–ò:\n"
            for metric, value in redis_metrics.items():
                if value and value != 'N/A':
                    context += f"   {metric}: {value}\n"
            context += "\n"
        
        # –ú–µ—Ç—Ä–∏–∫–∏ WebP
        if metrics.get('webp'):
            webp_metrics = metrics['webp']
            context += "üñºÔ∏è WEBP –ö–û–ù–í–ï–†–¢–ï–†:\n"
            for metric, value in webp_metrics.items():
                if value and value != 'N/A':
                    context += f"   {metric}: {value}\n"
            context += "\n"
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if metrics.get('system'):
            system_metrics = metrics['system']
            context += "üíª –°–ò–°–¢–ï–ú–ù–´–ï –ú–ï–¢–†–ò–ö–ò:\n"
            for metric, value in system_metrics.items():
                if value and value != 'N/A':
                    context += f"   {metric}: {value}\n"
            context += "\n"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à–∞
        if cache_stats:
            context += "üíæ –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–ï–®–ê:\n"
            if cache_stats.get('redis'):
                redis_stats = cache_stats['redis']
                context += "   Redis:\n"
                for key, value in redis_stats.items():
                    context += f"     {key}: {value}\n"
            if cache_stats.get('nginx'):
                nginx_stats = cache_stats['nginx']
                context += "   Nginx:\n"
                for key, value in nginx_stats.items():
                    context += f"     {key}: {value}\n"
            context += "\n"
        
        return context
    
    def _parse_analysis_result(self, analysis_text: str) -> AIAnalysisResult:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ AI-–∞–Ω–∞–ª–∏–∑–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
        try:
            # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å —Å –ø–æ–º–æ—â—å—é regex)
            lines = analysis_text.split('\n')
            problems = []
            recommendations = []
            performance_score = None
            forecast = None
            
            current_section = None
            for line in lines:
                line = line.strip()
                if '–ü–†–û–ë–õ–ï–ú–´' in line.upper() or '–ü–†–û–ë–õ–ï–ú' in line.upper():
                    current_section = 'problems'
                elif '–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò' in line.upper() or '–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò' in line.upper():
                    current_section = 'recommendations'
                elif '–ü–†–û–ì–ù–û–ó' in line.upper():
                    current_section = 'forecast'
                elif line.startswith('‚Ä¢') or line.startswith('-') or line.startswith('*'):
                    if current_section == 'problems':
                        problems.append(line[1:].strip())
                    elif current_section == 'recommendations':
                        recommendations.append(line[1:].strip())
                elif current_section == 'forecast' and line:
                    forecast = line
            
            return AIAnalysisResult(
                status="completed",
                problems=problems,
                recommendations=recommendations,
                performance_score=performance_score,
                forecast=forecast
            )
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ AI-–∞–Ω–∞–ª–∏–∑–∞: {e}")
            return AIAnalysisResult(
                status="error",
                problems=[f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}"],
                recommendations=[],
                performance_score=None,
                forecast=None
            )
    
    async def _perform_gpt_analysis(self, context: str) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å –ø–æ–º–æ—â—å—é GPT"""
        try:
            system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ DevOps –∏ —Å–∏—Å—Ç–µ–º–∞–º CDN. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã Bitrix CDN –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å:

1. –û–ë–©–ò–ô –°–¢–ê–¢–£–° —Å–∏—Å—Ç–µ–º—ã (—Ä–∞–±–æ—Ç–∞–µ—Ç/–µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã)
2. –ü–†–û–ë–õ–ï–ú–´ (–µ—Å–ª–∏ –µ—Å—Ç—å) —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
3. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
4. –ü–†–û–ì–ù–û–ó –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
5. –û–¶–ï–ù–ö–ê –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è."""

            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": context}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ GPT –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è GPT –∞–Ω–∞–ª–∏–∑–∞: {e}"
    
    async def analyze_trends(self, time_range: str = "1h") -> str:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ Prometheus
            
            context = f"–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥: {time_range}\n"
            context += "–î–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –ø–æ–ª—É—á–µ–Ω—ã –∏–∑ Prometheus..."
            
            system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç—Ä–µ–Ω–¥–æ–≤ –≤ —Å–∏—Å—Ç–µ–º–∞—Ö CDN. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–µ–Ω–¥—ã –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å:

1. –¢–†–ï–ù–î–´ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
2. –ü–ê–¢–¢–ï–†–ù–´ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
3. –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –Ω–∞–≥—Ä—É–∑–∫–∏
4. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º."""

            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": context}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {e}"
    
    async def ask_question(self, context: str) -> str:
        """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ –≤–æ–ø—Ä–æ—Å"""
        try:
            system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ DevOps –∏ —Å–∏—Å—Ç–µ–º–∞–º CDN. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã.

–ü—Ä–∞–≤–∏–ª–∞:
1. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
2. –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º
3. –ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–æ–≤
4. –ï—Å–ª–∏ –≤–∏–¥–∏—à—å –ø—Ä–æ–±–ª–µ–º—ã - –ø—Ä–µ–¥–ª–æ–∂–∏ —Ä–µ—à–µ–Ω–∏—è
5. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è
6. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏"""

            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": context}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞ –≤–æ–ø—Ä–æ—Å–∞: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}"
    
    async def analyze_code(self, configs_info: str) -> str:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π"""
        try:
            system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∫–æ–¥–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π —Å–∏—Å—Ç–µ–º CDN. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ª–æ–≥–∏ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.

–ù–∞–π–¥–∏:
1. –û–®–ò–ë–ö–ò –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ö
2. –ü–†–û–ë–õ–ï–ú–´ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
3. –ù–ï–û–ü–¢–ò–ú–ê–õ–¨–ù–´–ï –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
4. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ø–æ —É–ª—É—á—à–µ–Ω–∏—é

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º."""

            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:\n\n{configs_info}"}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞: {e}"
    
    async def find_issues(self, debug_info: str) -> str:
        """–ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º –≤ —Å–∏—Å—Ç–µ–º–µ"""
        try:
            system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ —Å–∏—Å—Ç–µ–º CDN. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –Ω–∞–π–¥–∏ –ø—Ä–æ–±–ª–µ–º—ã.

–ò—â–∏:
1. –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ø—Ä–æ–±–ª–µ–º—ã (–æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã)
2. –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–Ø (–Ω–µ–∑–¥–æ—Ä–æ–≤—ã–µ —Å–µ—Ä–≤–∏—Å—ã)
3. –ü–†–û–ë–õ–ï–ú–´ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
4. –û–®–ò–ë–ö–ò –≤ –ª–æ–≥–∞—Ö

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ."""

            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"–ù–∞–π–¥–∏ –ø—Ä–æ–±–ª–µ–º—ã –≤ —Å–∏—Å—Ç–µ–º–µ:\n\n{debug_info}"}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–±–ª–µ–º: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø—Ä–æ–±–ª–µ–º: {e}"
    
    async def get_suggestions(self, current_state: str) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º CDN. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –¥–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤—å:
1. –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ï —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
2. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
3. –ù–ê–°–¢–†–û–ô–ö–ò –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
4. –ú–û–ù–ò–¢–û–†–ò–ù–ì –∏ –∞–ª–µ—Ä—Ç—ã
5. –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º."""

            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"–î–∞–π —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:\n\n{current_state}"}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}"

    async def get_recommendations(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        try:
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            metrics = await self.prometheus.get_all_metrics()
            containers = await self.docker.get_containers_status()
            
            context = "=== –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò ===\n\n"
            context += "–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã:\n"
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
            running_containers = [c for c in containers if c['status'] == 'running']
            stopped_containers = [c for c in containers if c['status'] != 'running']
            
            context += f"–†–∞–±–æ—Ç–∞—é—â–∏—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {len(running_containers)}\n"
            context += f"–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {len(stopped_containers)}\n"
            
            if stopped_containers:
                context += f"–û—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ: {', '.join([c['name'] for c in stopped_containers])}\n"
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
            if metrics.get('redis'):
                redis_metrics = metrics['redis']
                context += f"\nRedis –º–µ—Ç—Ä–∏–∫–∏: {redis_metrics}\n"
            
            if metrics.get('nginx'):
                nginx_metrics = metrics['nginx']
                context += f"Nginx –º–µ—Ç—Ä–∏–∫–∏: {nginx_metrics}\n"
            
            system_prompt = """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º CDN. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å:

1. –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
2. –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò
3. –ù–ê–°–¢–†–û–ô–ö–ò –ö–ï–®–ò–†–û–í–ê–ù–ò–Ø
4. –ú–û–ù–ò–¢–û–†–ò–ù–ì –ò –ê–õ–ï–†–¢–´
5. –ú–ê–°–®–¢–ê–ë–ò–†–û–í–ê–ù–ò–ï

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º."""

            response = await openai.ChatCompletion.acreate(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": context}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
            return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}"
